---
title: "Chapter 6"
author: "Dominik Klepl"
date: "13 3 2018"
output: html_document
---
## R code 6.1
Example of overfitting by using too complex models, although their R2 will improve.
```{r}
#create data for this example - model brain volume as linear function of body mass
sppnames <- c( "afarensis","africanus","habilis","boisei",
    "rudolfensis","ergaster","sapiens")
brainvolcc <- c( 438 , 452 , 612, 521, 752, 871, 1350 )
masskg <- c( 37.0 , 35.5 , 34.5 , 41.5 , 55.5 , 61.0 , 53.5 )
d <- data.frame( species=sppnames , brain=brainvolcc , mass=masskg )

## R code 6.2

m6.1 <- lm( brain ~ mass , data=d )

## R code 6.3 - compute R2
R2 = function(model) {
  R2=1 - var(resid(model))/var(d$brain)
  return(R2)
}

## R code 6.4
m6.2 <- lm( brain ~ mass + I(mass^2) , data=d )

## R code 6.5
m6.3 <- lm( brain ~ mass + I(mass^2) + I(mass^3) , data=d )
m6.4 <- lm( brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4) ,
    data=d )
m6.5 <- lm( brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4) +
    I(mass^5) , data=d )

#this is actually so complex that it uses up all the degrees of freedom 
m6.6 <- lm( brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4) +
    I(mass^5) + I(mass^6) , data=d )

## R code 6.6
m6.7 <- lm( brain ~ 1 , data=d )

models=list(m6.1,m6.2,m6.3,m6.4,m6.5,m6.6,m6.7)

#R2 increases with more complex model - but it overfits at some point
for (m in models) {
  print(R2(m))
}
```

## R code 6.7 - Overthining box
```{r}
d.new <- d[ -i , ]

## R code 6.8
plot( brain ~ mass , d , col="slateblue" )
for ( i in 1:nrow(d) ) {
    d.new <- d[ -i , ]
    m0 <- lm( brain ~ mass, d.new )
    abline( m0 , col=col.alpha("black",0.5) )
}
```

## R code 6.9 Information Entropy function
```{r}
p <- c( 0.3 , 0.7 )
-sum( p*log(p) )
```

## R code 6.10 Deviance of a model
```{r}
# fit model with lm
m6.1 <- lm( brain ~ mass , d )

# compute deviance by cheating - R's logLik doesnt include the multiplication by -2 (look into why it's even there?)
(-2) * logLik(m6.1)
```

## R code 6.11 Overthinking box
How to compute deviance of the model manually (well, more manually). Here from a MAP estimates. logLik would work for MAP too.
```{r}
# standardize the mass before fitting
library(rethinking)
d$mass.s = (d$mass-mean(d$mass))/sd(d$mass)
m6.8 = map(
    alist(
        brain ~ dnorm( mu , sigma ) ,
        mu <- a + b*mass.s
    ) ,
    data=d ,
    start=list(a=mean(d$brain),b=0,sigma=sd(d$brain)) ,
    method="Nelder-Mead" )

# extract MAP estimates
theta = coef(m6.8)

# compute deviance
dev = (-2)*sum( dnorm(
            d$brain ,
            mean=theta[1]+theta[2]*d$mass.s ,
            sd=theta[3] ,
            log=TRUE ) )
dev
```

## R code 6.12
```{r}
N <- 20
kseq <- 1:5
dev <- sapply( kseq , function(k) {
        print(k);
        r <- replicate( 1e4 , sim.train.test( N=N, k=k ) );
        c( mean(r[1,]) , mean(r[2,]) , sd(r[1,]) , sd(r[2,]) )
    } )

## R code 6.13
dev <- sapply( kseq , function(k) {
        print(k);
        r <- mcreplicate( 1e3 , sim.train.test( N=N, k=k ) , mc.cores=3 );
        c( mean(r[1,]) , mean(r[2,]) , sd(r[1,]) , sd(r[2,]) )
    } )

## R code 6.14
plot( 1:5 , dev[1,] , ylim=c( min(dev[1:2,])-5 , max(dev[1:2,])+10 ) ,
    xlim=c(1,5.1) , xlab="number of parameters" , ylab="deviance" ,
    pch=16 , col=rangi2 )
mtext( concat( "N = ",N ) )
points( (1:5)+0.1 , dev[2,] )
for ( i in kseq ) {
    pts_in <- dev[1,i] + c(-1,+1)*dev[3,i]
    pts_out <- dev[2,i] + c(-1,+1)*dev[4,i]
    lines( c(i,i) , pts_in , col=rangi2 )
    lines( c(i,i)+0.1 , pts_out )
}
```

## R code 6.15 Overthinking box - computing WAIC manually
```{r}
data(cars)
m <- map(
    alist(
        dist ~ dnorm(mu,sigma),
        mu <- a + b*speed,
        a ~ dnorm(0,100),
        b ~ dnorm(0,10),
        sigma ~ dunif(0,30)
    ) , data=cars )
post <- extract.samples(m,n=1000)

## R code 6.16
n_samples <- 1000
ll <- sapply( 1:n_samples ,
    function(s) {
        mu <- post$a[s] + post$b[s]*cars$speed
        dnorm( cars$dist , mu , post$sigma[s] , log=TRUE )
    } )

## R code 6.17
n_cases <- nrow(cars)
lppd <- sapply( 1:n_cases , function(i) log_sum_exp(ll[i,]) - log(n_samples) )

## R code 6.18
pWAIC <- sapply( 1:n_cases , function(i) var(ll[i,]) )

## R code 6.19
-2*( sum(lppd) - sum(pWAIC) )

## R code 6.20
waic_vec <- -2*( lppd - pWAIC )
sqrt( n_cases*var(waic_vec) )
```

## R code 6.21 Model comparison
```{r}
#Use milk data, remove NAs and rescale neocortex variable (from % to decimals)
data(milk)
d <- milk[ complete.cases(milk) , ]
d$neocortex <- d$neocortex.perc / 100
dim(d)


## R code 6.22 - fit 4 different models with 2 predictors 
#also estimate log sigma - to constrain it to be only positive (exp(x) is always larger than zero)
#provide start values for MAP function
a.start <- mean(d$kcal.per.g)
sigma.start <- log(sd(d$kcal.per.g))

#model 1 with only intercept
m6.11 <- map(
    alist(
        kcal.per.g ~ dnorm( a , exp(log.sigma) )
    ) ,
    data=d , start=list(a=a.start,log.sigma=sigma.start) )

#model 2 using % of neocortex
m6.12 <- map(
    alist(
        kcal.per.g ~ dnorm( mu , exp(log.sigma) ) ,
        mu <- a + bn*neocortex
    ) ,
    data=d , start=list(a=a.start,bn=0,log.sigma=sigma.start) )

#model 3 using log_mass as predictor
m6.13 <- map(
    alist(
        kcal.per.g ~ dnorm( mu , exp(log.sigma) ) ,
        mu <- a + bm*log(mass)
    ) ,
    data=d , start=list(a=a.start,bm=0,log.sigma=sigma.start) )

#model 4 for using both predictors
m6.14 <- map(
    alist(
        kcal.per.g ~ dnorm( mu , exp(log.sigma) ) ,
        mu <- a + bn*neocortex + bm*log(mass)
    ) ,
    data=d , start=list(a=a.start,bn=0,bm=0,log.sigma=sigma.start) )
```

## R code 6.23 Comparing WAIC values
```{r}
WAIC( m6.14 )

```

## R code 6.24
Instead of using WAIC function for all models there is compare() function that does that for us +ranks the models from best to worst
```{r}
milk.models = compare( m6.11 , m6.12 , m6.13 , m6.14 )
milk.models

## R code 6.25
plot( milk.models , SE=TRUE , dSE=TRUE )
```

## R code 6.26
Calculate probability that the difference between m6.14 and m6.11 is not positive (14>11) but in fact negative (reverse)
```{r}
diff <- rnorm( 1e5 , 6.7 , 7.26 )
sum(diff<0)/1e5
```

## R code 6.27 Comparing estimates
coeftab constructs a table to do this better. We can be interested how the estimates change or don't change across models etc. We can also plot the coeftab output.
```{r}
coeftab(m6.11,m6.12,m6.13,m6.14)

## R code 6.28
plot( coeftab(m6.11,m6.12,m6.13,m6.14) )
```

## R code 6.29 Model averaging
We can predict new data while preserving the uncertainty about the estimates.
```{r}
# compute counterfactual predictions
# neocortex from 0.5 to 0.8
nc.seq <- seq(from=0.5,to=0.8,length.out=30)
d.predict <- list(
    kcal.per.g = rep(0,30), # empty outcome
    neocortex = nc.seq,     # sequence of neocortex
    mass = rep(4.5,30)      # average mass
)
pred.m6.14 <- link( m6.14 , data=d.predict )
mu <- apply( pred.m6.14 , 2 , mean )
mu.PI <- apply( pred.m6.14 , 2 , PI )

# plot it all
plot( kcal.per.g ~ neocortex , d , col=rangi2 )
lines( nc.seq , mu , lty=2 )
lines( nc.seq , mu.PI[1,] , lty=2 )
lines( nc.seq , mu.PI[2,] , lty=2 )
```

## R code 6.30
Similarly we can predict new data using all models to preserve the uncertainty about which one is the best one. Ensemble function does that by averaging predictions from all models and using Akaike weights as proportions.
```{r}
milk.ensemble <- ensemble( m6.11 , m6.12 , m6.13 , m6.14 , data=d.predict )
mu <- apply( milk.ensemble$link , 2 , mean )
mu.PI <- apply( milk.ensemble$link , 2 , PI )

#and plot it
plot( kcal.per.g ~ neocortex , d , col=rangi2 )
lines( nc.seq , mu )
shade( mu.PI , nc.seq )
```

## R code 6.31
library(rethinking)
data(Howell1)
d <- Howell1
d$age <- (d$age - mean(d$age))/sd(d$age)
set.seed( 1000 )
i <- sample(1:nrow(d),size=nrow(d)/2)
d1 <- d[ i , ]
d2 <- d[ -i , ]

## R code 6.32
sum( dnorm( d2$height , mu , sigma , log=TRUE ) )
```

